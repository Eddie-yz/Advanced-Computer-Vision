{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute camera motion from optical flow computed using SPyNet. We first uniformly sample points in an image, then consider the flow-displaced point in the other image as a match. A modified PyTorch implementation of SPyNet is provided in directory  $\\mathtt{Flow}$.\n",
    "1. Go to $\\mathtt{Flow}$ and run $\\mathtt{demo\\_spynet.py}$. \n",
    "2. Run the following script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Rui Zhu (rzhu@eng.ucsd.edu)\n",
    "# For CSE152B Spring 2020 HW1\n",
    "# Apr 15, 2020\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "import viso2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import time\n",
    "import scipy.io as io\n",
    "import os.path as osp\n",
    "\n",
    "def errorMetric(RPred, RGt, TPred, TGt):\n",
    "    diffRot = (RPred - RGt)\n",
    "    diffTrans = (TPred - TGt)\n",
    "    errorRot = np.sqrt(np.sum(np.multiply(diffRot.reshape(-1), diffRot.reshape(-1))))\n",
    "    errorTrans = np.sqrt(np.sum(np.multiply(diffTrans.reshape(-1), diffTrans.reshape(-1))))\n",
    "\n",
    "    return errorRot, errorTrans\n",
    "\n",
    "if_vis = True # set to True to do the visualization per frame; the images will be saved at '.vis/'. Turn off if you just want the camera poses and errors\n",
    "if_on_screen = True # if True the visualization per frame is going to be displayed realtime on screen; if False there will be no display, but in both options the images will be saved\n",
    "\n",
    "# parameter settings (for an example, please download\n",
    "# dataset_path = '../dataset'\n",
    "dataset_path = '/datasets/cse152-252-sp20-public/dataset_SfM' # On the ``ieng6.ucsd.edu`` server\n",
    "img_dir      = os.path.join(dataset_path, 'sequences/00/image_0')\n",
    "gt_dir       = os.path.join(dataset_path, 'poses/00.txt')\n",
    "calibFile    = os.path.join(dataset_path, 'sequences/00/calib.txt')\n",
    "border       = 50;\n",
    "gap          = 15;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the camera calibration information\n",
    "with open(calibFile) as fid:\n",
    "    calibLines = fid.readlines()\n",
    "    calibLines = [calibLine.strip() for calibLine in calibLines]\n",
    "\n",
    "calibInfo = [float(calibStr) for calibStr in calibLines[0].split(' ')[1:]]\n",
    "# param = {'f': calibInfo[0], 'cu': calibInfo[2], 'cv': calibInfo[6]}\n",
    "\n",
    "# Load the ground-truth depth and rotation\n",
    "with open(gt_dir) as fid:\n",
    "    gtTr = [[float(TrStr) for TrStr in line.strip().split(' ')] for line in fid.readlines()]\n",
    "gtTr = np.asarray(gtTr).reshape(-1, 3, 4)\n",
    "\n",
    "# param['height'] = 1.6\n",
    "# param['pitch']  = -0.08\n",
    "# param['match'] = {'pre_step_size': 64}\n",
    "first_frame  = 0\n",
    "last_frame   = 300\n",
    "\n",
    "# init visual odometry\n",
    "params = viso2.Mono_parameters()\n",
    "params.calib.f = calibInfo[0]\n",
    "params.calib.cu = calibInfo[2]\n",
    "params.calib.cv = calibInfo[6]\n",
    "params.height = 1.6\n",
    "params.pitch = -0.08\n",
    "params.match.pre_step_size = 64\n",
    "\n",
    "# matcher_params = viso2.Matcher_parameters()\n",
    "# matcher_params.pre_step_size = 64\n",
    "\n",
    "first_frame  = 0\n",
    "last_frame   = 300\n",
    "\n",
    "# init transformation matrix array\n",
    "Tr_total = []\n",
    "Tr_total_np = []\n",
    "Tr_total.append(viso2.Matrix_eye(4))\n",
    "Tr_total_np.append(np.eye(4))\n",
    "\n",
    "# init viso module\n",
    "visoMono = viso2.VisualOdometryMono(params)\n",
    "\n",
    "\n",
    "if if_vis:\n",
    "    save_path = 'vis'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    ax1 = plt.subplot(211)\n",
    "    ax1.axis('off')\n",
    "    ax2 = plt.subplot(212)\n",
    "    ax2.set_xticks(np.arange(-100, 100, step=10))\n",
    "    ax2.set_yticks(np.arange(-500, 500, step=10))\n",
    "    ax2.axis('equal')\n",
    "    ax2.grid()\n",
    "    if if_on_screen:\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all frames do\n",
    "if_replace = False\n",
    "errorTransSum = 0\n",
    "errorRotSum = 0\n",
    "errorRot_list = []\n",
    "errorTrans_list =[]\n",
    "feature_dir = 'Flow'\n",
    "\n",
    "for frame in range(first_frame, last_frame):\n",
    "    # 1-based index\n",
    "    k = frame-first_frame+1\n",
    "\n",
    "    # read current images\n",
    "    I = imread(os.path.join(img_dir, '%06d.png'%frame))\n",
    "    assert(len(I.shape) == 2) # should be grayscale\n",
    "\n",
    "\n",
    "    if frame > 0:\n",
    "        flow = np.ascontiguousarray(\n",
    "                np.load( osp.join(feature_dir, '%06d_flow.npy' % frame ) ) )\n",
    "\n",
    "        height, width = I.shape\n",
    "        u1, v1 = np.meshgrid(np.arange(0, width), np.arange(0, height ) )\n",
    "        u2 = u1 + flow[:, :, 0]\n",
    "        v2 = v1 + flow[:, :, 1]\n",
    "\n",
    "        u1 = u1[border:-border:gap, border:-border:gap ]\n",
    "        v1 = v1[border:-border:gap, border:-border:gap ]\n",
    "        u2 = u2[border:-border:gap, border:-border:gap ]\n",
    "        v2 = v2[border:-border:gap, border:-border:gap ]\n",
    "        u1 = u1.reshape(-1, 1 )\n",
    "        v1 = v1.reshape(-1, 1 )\n",
    "        u2 = u2.reshape(-1, 1 )\n",
    "        v2 = v2.reshape(-1, 1 )\n",
    "        preMatches = np.concatenate([u1, v1, u2, v2], axis=1 )\n",
    "        preMatches = preMatches.astype(np.float32 )\n",
    "        preMatches = np.ascontiguousarray(preMatches )\n",
    "\n",
    "        # compute egomotion\n",
    "        print(preMatches.shape )\n",
    "        process_result = visoMono.process_frame_preMatch(preMatches )\n",
    "\n",
    "        Tr = visoMono.getMotion()\n",
    "        matrixer = viso2.Matrix(Tr)\n",
    "        Tr_np = np.zeros((4, 4) )\n",
    "        Tr.toNumpy(Tr_np) # so awkward...\n",
    "        matches_np = preMatches\n",
    "    else:\n",
    "        matches_np = np.zeros((4, 0), dtype = np.float32 )\n",
    "\n",
    "    # accumulate egomotion, starting with second frame\n",
    "    if k > 1:\n",
    "        if process_result is False:\n",
    "            if_replace = True\n",
    "            Tr_total.append(Tr_total[-1])\n",
    "            Tr_total_np.append(Tr_total_np[-1])\n",
    "        else:\n",
    "            if_replace = False\n",
    "            Tr_total.append(Tr_total[-1] * viso2.Matrix_inv(Tr))\n",
    "            Tr_total_np.append(Tr_total_np[-1] @ np.linalg.inv(Tr_np)) # should be the same\n",
    "            print(Tr_total_np[-1])\n",
    "\n",
    "    # output statistics\n",
    "    num_matches = visoMono.getNumberOfMatches()\n",
    "    num_inliers = visoMono.getNumberOfInliers()\n",
    "    #matches = visoMono.getMatches()\n",
    "\n",
    "\n",
    "    matches_np = matches_np.transpose()\n",
    "    if if_vis:\n",
    "        # update image\n",
    "        ax1.clear()\n",
    "        ax1.imshow(I, cmap='gray', vmin=0, vmax=255)\n",
    "        if num_inliers != 0:\n",
    "            for n in range(num_matches):\n",
    "                ax1.plot([matches_np[0, n], matches_np[2, n]], [matches_np[1, n], matches_np[3, n]])\n",
    "        ax1.set_title('Frame %d'%frame)\n",
    "\n",
    "        # update trajectory\n",
    "        if k > 1:\n",
    "            ax2.plot([Tr_total_np[k-2][0, 3], Tr_total_np[k-1][0, 3]], \\\n",
    "                [Tr_total_np[k-2][2, 3], Tr_total_np[k-1][2, 3]], 'b.-', linewidth=1)\n",
    "            ax2.plot([gtTr[k-2][0, 3], gtTr[k-1][0, 3]], \\\n",
    "                [gtTr[k-2][2, 3], gtTr[k-1][2, 3]], 'r.-', linewidth=1)\n",
    "        ax2.set_title('Blue: estimated trajectory; Red: ground truth trejectory')\n",
    "\n",
    "        plt.draw()\n",
    "\n",
    "    # Compute rotation\n",
    "    Rpred_p = Tr_total_np[k-2][0:3, 0:3]\n",
    "    Rpred_c = Tr_total_np[k-1][0:3, 0:3]\n",
    "    Rpred = Rpred_c.transpose() @ Rpred_p\n",
    "    Rgt_p = np.squeeze(gtTr[k-2, 0:3, 0:3])\n",
    "    Rgt_c = np.squeeze(gtTr[k-1, 0:3, 0:3])\n",
    "    Rgt = Rgt_c.transpose() @ Rgt_p\n",
    "    # Compute translation\n",
    "    Tpred_p = Tr_total_np[k-2][0:3, 3:4]\n",
    "    Tpred_c = Tr_total_np[k-1][0:3, 3:4]\n",
    "    Tpred = Tpred_c - Tpred_p\n",
    "    Tgt_p = gtTr[k-2, 0:3, 3:4]\n",
    "    Tgt_c = gtTr[k-1, 0:3, 3:4]\n",
    "    Tgt = Tgt_c - Tgt_p\n",
    "    # Compute errors\n",
    "    errorRot, errorTrans = errorMetric(Rpred, Rgt, Tpred, Tgt)\n",
    "    errorRotSum = errorRotSum + errorRot\n",
    "    errorTransSum = errorTransSum + errorTrans\n",
    "    # errorRot_list.append(errorRot)\n",
    "    # errorTrans_list.append(errorTrans)\n",
    "    print('Mean Error Rotation: %.5f'%(errorRotSum / (k-1)))\n",
    "    print('Mean Error Translation: %.5f'%(errorTransSum / (k-1)))\n",
    "\n",
    "\n",
    "\n",
    "    print('== [Result] Frame: %d, Matches %d, Inliers: %.2f'%(frame, num_matches, 100*num_inliers/(num_matches+1e-8)))\n",
    "\n",
    "    if if_vis:\n",
    "        # input('Paused; Press Enter to continue') # Option 1: Manually pause and resume\n",
    "        if if_on_screen:\n",
    "            plt.pause(0.1) # Or Option 2: enable to this to auto pause for a while after daring to enable animation in case of a delay in drawing\n",
    "        vis_path = os.path.join(save_path, 'frame%03d.jpg'%frame)\n",
    "        fig.savefig(vis_path)\n",
    "        print('Saved at %s'%vis_path)\n",
    "        \n",
    "        if frame % 50 == 0:\n",
    "            plt.figure(figsize=(10, 15))\n",
    "            plt.imshow(plt.imread(vis_path))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# input('Press Enter to exit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Does SPyNet yield higher accuracy than the original {\\tt libviso2}? If so, why? If not, what steps can you take to improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain how SPyNet achieves accurate flow with significantly lower computational cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
